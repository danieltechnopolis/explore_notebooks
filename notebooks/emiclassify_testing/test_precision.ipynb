{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74245235",
   "metadata": {},
   "source": [
    "#### Callibrate decision thresholds for company classification \n",
    "\n",
    "The following notebook is designed to provide a quick way to run precision metrics on the classified DataFrames outputted by the openAI batch processing. \n",
    "The high-level implementation follows the logic of: \n",
    "1. Merging the binary and probabilistic results\n",
    "2. Apply boolean mask to binary classification 'answer' column\n",
    "3. Transform 'Probabability' and 'answer' columns to numpy arrays y_true and y_pred\n",
    "4. Visualise PR curve to identify consistencies in models decision boundary \n",
    "\n",
    "In other words we aim to visualise how well the models binary classification boundaires allign with its probabaistic prediction confidence. This should improve the overall performance of the model when running real test data by ensuring that the the cut-off theshold is set to minimise the actual decision uncertainty. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b212ad86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from precision_recall import *\n",
    "from sklearn.metrics import precision_score, recall_score, precision_recall_curve, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e89a8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "DATA_PATH = os.getenv(\"DATA_DIR\")\n",
    "\n",
    "file_path_1 = os.path.join(DATA_PATH, 'Electronics_batch_P_test.csv')\n",
    "file_path_2 = os.path.join(DATA_PATH, 'Electronics_batch_test2.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2f966b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_binary = pd.read_csv(file_path_2)\n",
    "\n",
    "df_prob = pd.read_csv(file_path_1)\n",
    "\n",
    "\n",
    "merged_df = pd.merge(\n",
    "    df_binary,\n",
    "    df_prob[['org_ID', 'Probability']],\n",
    "    on='org_ID',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "merged_df= merged_df[['Probability', 'answer','org_ID','organisation_name', 'description', 'short_description', 'y_true']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d442bd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.read_excel(file_path_2)\n",
    "\n",
    "y_true = merged_df['y_true'].to_numpy()\n",
    "\n",
    "y_pred = merged_df['answer'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe8e807",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {'no': 0, 'yes': 1}\n",
    "\n",
    "y_pred = np.array([label_map[x] for x in y_pred])\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(y_true, y_pred)\n",
    "\n",
    "# Plot the PR curve (precision vs recall)\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(recall, precision, marker='.', label='PR curve')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('PR curve electronics n=368')\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c0eba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, thresholds = precision_recall_curve(y_true, y_pred)\n",
    "f1_scores = 2 * (precision * recall) / (precision + recall + 1e-8)  \n",
    "best_idx = np.argmax(f1_scores)\n",
    "best_threshold = thresholds[best_idx]\n",
    "\n",
    "print(f\"optimal threshold (F1): {best_threshold:.3f}\")\n",
    "print(f\"Precision: {precision[best_idx]:.3f}\")\n",
    "print(f\"Recall:    {recall[best_idx]:.3f}\")\n",
    "print(f\"F1:        {f1_scores[best_idx]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f6c38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_binary = (y_pred >= 0.5).astype(int)\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred_binary)\n",
    "\n",
    "# Display confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Negative\", \"Positive\"])\n",
    "disp.plot(cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix (threshold=0.5)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007f5a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = precision_recall(y_true, y_pred)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Negative\", \"Positive\"])\n",
    "disp.plot(cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95726107",
   "metadata": {},
   "source": [
    "##### Generate a validation dataset composed of multiple ecosystems\n",
    "\n",
    "The following code aims to acheive the following for each ecosystem: \n",
    "1. Construct an unbalanced labelled dataset containing companies in agrifood, tourism, and textiles\n",
    "2. Dummy code each ecosystem in the 'source' column to generate y_true array (according to each ecosytem classification run)\n",
    "3. Boolean transform on answer column from 'yes' / 'no' to 1 / 0 to generate y_pred array\n",
    "4. Compute precision metrics on arrays \n",
    "5. generate visualisation as a TP, FP, FN, TN bar plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217ef9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "xls = pd.ExcelFile(file_path)\n",
    "dfs = {sheet_name: xls.parse(sheet_name) for sheet_name in xls.sheet_names}\n",
    "agri_df = dfs['Agrifood']\n",
    "tourism_df = dfs['Tourism']\n",
    "textile_df = dfs['Textiles']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031dfb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "industry_dummy = {\n",
    "    'Agrifood': {'Agrifood': 1, 'Tourism': 0, 'Textiles': 0},\n",
    "    'Tourism':  {'Agrifood': 0, 'Tourism': 1, 'Textiles': 0},\n",
    "    'Textiles': {'Agrifood': 0, 'Tourism': 0, 'Textiles': 1}\n",
    "}\n",
    "\n",
    "label_map_pred = {'no': 0, 'yes': 1}\n",
    "\n",
    "precision_scores = {}\n",
    "\n",
    "for indsutry in ['Agrifood', 'Tourism', 'Textiles']:\n",
    "    df = dfs[indsutry]\n",
    "    label_df = df[['org_ID', 'answer', 'source']]\n",
    "    \n",
    "    # Map predictions\n",
    "    y_pred = label_df['answer'].map(label_map_pred).to_numpy()\n",
    "    y_true = label_df['source'].map(industry_dummy[indsutry]).to_numpy()\n",
    "    \n",
    "    print(f\"\\nSector: {indsutry}\")\n",
    "    precision_recall(y_true, y_pred)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16aced92",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tp = (y_true == 1) & (y_pred == 1)   \n",
    "fn = (y_true == 1) & (y_pred == 0)   \n",
    "fp = (y_true == 0) & (y_pred == 1)\n",
    "tn = (y_true == 0) & (y_pred == 0) \n",
    "\n",
    "\n",
    "outcomes = np.zeros_like(y_true, dtype='<U2')\n",
    "outcomes[tp] = 'TP'\n",
    "outcomes[fn] = 'FN'\n",
    "outcomes[fp] = 'FP'\n",
    "outcomes[tn] = 'TN'\n",
    "\n",
    "\n",
    "counts = Counter(outcomes)\n",
    "labels = ['TP', 'FP', 'FN', 'TN']\n",
    "values = [counts.get(label, 0) for label in labels]\n",
    "\n",
    "plt.figure(figsize=(7, 5))\n",
    "plt.bar(labels, values, color=['green', 'orange', 'red', 'blue'])\n",
    "plt.title('Model prediction outcome')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
