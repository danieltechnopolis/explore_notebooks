{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30183a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from spacy.matcher import PhraseMatcher\n",
    "from import_keywords import clean_text\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace7b0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "DATA_PATH = os.getenv(\"DATA_DIR\")\n",
    "print(f\"DATA_PATH: {DATA_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54d677d",
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords_df = pd.read_excel(DATA_PATH + \"/keywords_combined_digital/Keywords_Combined.xlsx\", sheet_name=\"Sheet1\")\n",
    "keywords_df = keywords_df[keywords_df['yes/no'] == 'yes']\n",
    "keywords_df['Keyword'] = keywords_df['Keyword'].astype(str).str.strip().str.lower()\n",
    "keywords_df = keywords_df.drop(columns=['yes/no', 'Subcluster', 'Cluster'])\n",
    "keywords_df['Keyword'] = (\n",
    "    keywords_df['Keyword']\n",
    "    .astype(str)           \n",
    "    .str.strip()          \n",
    "    .str.lower()          \n",
    ")\n",
    "\n",
    "\n",
    "companies_df = pd.read_csv(DATA_PATH + \"/cb_net0_companies_concat.csv\", \n",
    "    usecols=['org_ID', 'organisation_name', 'short_description', 'description', 'data_source'],\n",
    "    dtype={'org_ID': 'string', 'organisation_name': 'string', 'short_description': 'string', 'description': 'string'},\n",
    "    index_col=False)\n",
    "companies_df = companies_df[companies_df['data_source'] != 'net0']\n",
    "\n",
    "print(companies_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329b3332",
   "metadata": {},
   "outputs": [],
   "source": [
    "companies_df['search_text'] = (\n",
    "    (companies_df['short_description'].fillna('') + ' ' + companies_df['description'].fillna(''))\n",
    "    .str.lower()\n",
    "    .str.replace(r'[^\\w\\s]', ' ', regex=True)\n",
    "    .str.replace(r'\\s+', ' ', regex=True)\n",
    "    .str.strip()\n",
    ")\n",
    "\n",
    "companies_df.drop(['short_description', 'description'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18b9020",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_md')\n",
    "keyword_texts = keywords_df['Keyword'].unique()\n",
    "keyword_docs = [nlp(kw) for kw in keyword_texts]\n",
    "keyword_vectors = np.vstack([doc.vector for doc in keyword_docs if doc.has_vector and doc.vector_norm > 0])\n",
    "keyword_texts = np.array([kw for kw, doc in zip(keyword_texts, keyword_docs) if doc.has_vector and doc.vector_norm > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46fb0c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = companies_df['search_text'].tolist()\n",
    "company_vectors = []\n",
    "\n",
    "for doc in nlp.pipe(texts, batch_size=1000, n_process=1):  \n",
    "    if doc.has_vector and doc.vector_norm > 0:\n",
    "        company_vectors.append(doc.vector)\n",
    "    else:\n",
    "        company_vectors.append(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474de445",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(DATA_PATH +'/tech_keyword_filtering/keyword_spacey_embeddings.npz', vectors=keyword_vectors, texts=keyword_texts)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
