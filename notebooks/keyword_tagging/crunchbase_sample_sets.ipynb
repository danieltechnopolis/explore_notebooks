{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6283f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d041a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()                                    \n",
    "\n",
    "FILE_PATH = os.getenv(\"DATA_DIR\")               \n",
    "SAVE_DIR  = os.getenv(\"SAVE_DIR\")      \n",
    "WORKBOOK  = \"ecosystems_sample_data.xlsx\"\n",
    "out_path  = os.path.join(SAVE_DIR, WORKBOOK)             \n",
    "os.makedirs(SAVE_DIR, exist_ok=True)             \n",
    "\n",
    "        \n",
    "WORKBOOK  = \"ecosystems_sample_data.xlsx\"\n",
    "out_path  = os.path.join(SAVE_DIR, WORKBOOK)                     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c1428a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cb_df = pd.read_excel(\n",
    "    FILE_PATH,          \n",
    "    sheet_name=1,       \n",
    "    engine=\"openpyxl\",  \n",
    "    header=0,           \n",
    "    dtype=str        \n",
    ")\n",
    "\n",
    "print(f\"Loaded {cb_df.shape[0]:,} rows × {cb_df.shape[1]} columns.\")\n",
    "print(cb_df.columns.tolist())        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e78617",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def generate_samplesets(\n",
    "    df: pd.DataFrame,\n",
    "    ecosystems,                       # str | list-like of str\n",
    "    n: int = 150,\n",
    "    tgt = None,                       # None=SRS · \"auto\"=proportional · 0–1=float\n",
    "    label_col: str = \"Is_True\",\n",
    "    eco_col: str = \"Ecosystem\",\n",
    "    seed: int | None = 42\n",
    ") -> dict[str, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Sample `n` rows for one or more ecosystems.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict : {ecosystem_name -> sampled DataFrame}\n",
    "    \"\"\"\n",
    "    # normalise ecosystems → list\n",
    "    if isinstance(ecosystems, (str, bytes)):\n",
    "        ecosystems = [ecosystems]\n",
    "    ecosystems = list(ecosystems)               # make indexable\n",
    "\n",
    "    samples = {}\n",
    "    for eco in ecosystems:\n",
    "        d = df[df[eco_col] == eco]\n",
    "        if len(d) < n:\n",
    "            raise ValueError(f\"{eco}: only {len(d)} rows; need {n}.\")\n",
    "\n",
    "        # --- design\n",
    "        if tgt is None:                         # Simple Random Sample\n",
    "            sample = d.sample(n, random_state=seed)\n",
    "        else:                                   # Stratified\n",
    "            tgt_pct = (d[label_col].eq(\"Yes\").mean()\n",
    "                       if tgt == \"auto\" else float(tgt))\n",
    "            y_n = int(round(n * tgt_pct)); n_n = n - y_n\n",
    "            y  = d[d[label_col] == \"Yes\"].sample(y_n, random_state=seed)\n",
    "            n_ = d[d[label_col] == \"No\" ].sample(n_n, random_state=seed)\n",
    "            sample = pd.concat([y, n_]).sample(frac=1, random_state=seed)\n",
    "\n",
    "        samples[eco] = sample.copy()\n",
    "    \n",
    "    # return dict normally; but if only one ecosystem was asked for, return the DF directly\n",
    "    if len(ecosystems) == 1:\n",
    "        return samples[ecosystems[0]]\n",
    "    return samples\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def count_label_distribution(\n",
    "    eco_samples, \n",
    "    label_col=\"Is_True\", \n",
    "    labels=(\"Yes\", \"No\")\n",
    "):\n",
    "    \"\"\"\n",
    "    Counts the number of 'Yes' and 'No' (case-insensitive) in label_col for each ecosystem sample.\n",
    "\n",
    "    Returns a DataFrame:\n",
    "    | Ecosystem | Yes | No |\n",
    "    \"\"\"\n",
    "    # Normalize labels to lowercase for matching\n",
    "    labels_lower = [l.lower() for l in labels]\n",
    "    rows = []\n",
    "    for eco, df in eco_samples.items():\n",
    "        # Convert column values to lowercase, strip whitespace\n",
    "        values = df[label_col].str.lower().str.strip()\n",
    "        counts = values.value_counts().reindex(labels_lower).fillna(0).astype(int)\n",
    "        # Map back to original label order for DataFrame\n",
    "        rows.append({\n",
    "            \"Ecosystem\": eco,\n",
    "            labels[0]: counts.get(labels_lower[0], 0),\n",
    "            labels[1]: counts.get(labels_lower[1], 0)\n",
    "        })\n",
    "    return pd.DataFrame(rows).set_index(\"Ecosystem\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad12179c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ecosystems = cb_df[\"Ecosystem\"].dropna().unique()\n",
    "eco_samples = generate_samplesets(cb_df, ecosystems, n=150, tgt=\"auto\", seed=42)\n",
    "sampling_dist = count_label_distribution(eco_samples)\n",
    "print(sampling_dist)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b7fb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure consistent order (alphabetical by ecosystem)\n",
    "sampling_dist = sampling_dist.sort_index()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 7))\n",
    "\n",
    "# Bar width\n",
    "bar_width = 0.35\n",
    "x = range(len(sampling_dist.index))\n",
    "\n",
    "# Bar positions\n",
    "bar1 = [val for val in sampling_dist[\"Yes\"]]\n",
    "bar2 = [val for val in sampling_dist[\"No\"]]\n",
    "\n",
    "# Plot bars\n",
    "rects1 = ax.bar([i - bar_width/2 for i in x], bar1, bar_width, label=\"Yes\", color=\"#3498db\")\n",
    "rects2 = ax.bar([i + bar_width/2 for i in x], bar2, bar_width, label=\"No\",  color=\"#e74c3c\")\n",
    "\n",
    "# Customization\n",
    "ax.set_xticks(list(x))\n",
    "ax.set_xticklabels(sampling_dist.index, rotation=30, ha='right', fontsize=11)\n",
    "ax.set_ylabel(\"Sample Count\", fontsize=13)\n",
    "ax.set_xlabel(\"Ecosystem\", fontsize=13)\n",
    "ax.set_title(\"Distribution of 'Yes' and 'No' Labels by Ecosystem\", fontsize=15, pad=20)\n",
    "ax.legend(title=\"Is_True Label\", fontsize=12)\n",
    "\n",
    "# Annotate bars\n",
    "for rect in rects1 + rects2:\n",
    "    height = rect.get_height()\n",
    "    if height > 0:\n",
    "        ax.annotate(f\"{height}\",\n",
    "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                    xytext=(0, 3),  # 3 points vertical offset\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom', fontsize=10, color='black')\n",
    "\n",
    "ax.spines[\"top\"].set_visible(False)\n",
    "ax.spines[\"right\"].set_visible(False)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85332475",
   "metadata": {},
   "outputs": [],
   "source": [
    "textile_sample = generate_samplesets(cb_df, \"Textiles\", n=150, tgt=None)\n",
    "textile_sample_auto = generate_samplesets(cb_df, \"Textiles\", n=150, tgt=\"auto\")\n",
    "\n",
    "# prep counts\n",
    "cnt_textile = textile_sample[\"Is_True\"].value_counts().reindex(labels).fillna(0)\n",
    "cnt_textile_auto = textile_sample_auto[\"Is_True\"].value_counts().reindex(labels).fillna(0)\n",
    "# plot side-by-side\n",
    "x     = np.arange(len(labels))          \n",
    "width = 0.35\n",
    "fig, ax = plt.subplots()\n",
    "ax.bar(x - width/2, cnt_textile, width, label=\"Random\")\n",
    "ax.bar(x + width/2, cnt_textile_auto, width, label=\"Proportional\")\n",
    "ax.set_title(\"Textiles – Is_True distribution (150-row samples)\")\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels)\n",
    "ax.set_ylabel(\"Count\")\n",
    "ax.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15729cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function parameters\n",
    "N           = 150          # rows per ecosystem\n",
    "YES_POLICY  = None         # None=SRS · \"auto\"=proportional · 0–1=float\n",
    "SEED        = 42\n",
    "WORKBOOK    = \"ecosystems_sample_data.xlsx\"   # output file name\n",
    "\n",
    "\n",
    "\n",
    "# %% ── 1. list ecosystems ───────────────────────────────────────────────\n",
    "ecosystems = cb_df[\"Ecosystem\"].dropna().unique()\n",
    "\n",
    "# Run function to extract sample data N = 150 rows per ecosystem\n",
    "# and save to dictionary\n",
    "# (ecosystem name as key, DataFrame as value)\n",
    "eco_samples = generate_samplesets(\n",
    "    cb_df,\n",
    "    ecosystems,\n",
    "    n   = N,\n",
    "    tgt = YES_POLICY,\n",
    "    seed= SEED\n",
    ")\n",
    "\n",
    "# %% ── 3. add annotation columns ────────────────────────────────────────\n",
    "for df in eco_samples.values():\n",
    "    df[\"Human_Label\"] = \"\"\n",
    "   \n",
    "\n",
    "# %% ── 4. merge for programmatic work ───────────────────────────────────\n",
    "merged_sample_data = (\n",
    "    pd.concat(eco_samples.values(), ignore_index=True)\n",
    "      .reset_index(drop=True)\n",
    ")\n",
    "print(f\"merged_sample_data shape: {merged_sample_data.shape}\")\n",
    "\n",
    "#  ── 5. export workbook with trimmed columns ──────────────────────────\n",
    "keep_cols = [\n",
    "    \"name\", \"domain\", \"permalink\", \"short_description\",\n",
    "     \"description\", \"Human_Label\"\n",
    "]\n",
    "\n",
    "# Write sample data to an excel workbook\n",
    "# with one sheet per ecosystem\n",
    "with pd.ExcelWriter(out_path, engine=\"xlsxwriter\") as writer:\n",
    "    for eco, df in eco_samples.items():\n",
    "        df_reduced = df.reindex(columns=keep_cols)\n",
    "        df_reduced.to_excel(writer,\n",
    "                            sheet_name=eco[:31] or \"Sheet\",\n",
    "                            index=False)\n",
    "\n",
    "        # ── format after the sheet is created \n",
    "        ws = writer.sheets[eco[:31] or \"Sheet\"]\n",
    "        wb = writer.book\n",
    "        wrap = wb.add_format({\"text_wrap\": True, \"valign\": \"top\"})\n",
    "\n",
    "        # A:F → the six columns we kept; set width = 45 chars & wrap\n",
    "        ws.set_column(\"A:F\", 45, wrap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fa7614",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "data_dir  = os.path.dirname(FILE_PATH)\n",
    "AERO_FILE = os.path.join(data_dir, \"Aerospace_merged.xlsx\")\n",
    "\n",
    "aero_df = pd.read_excel(AERO_FILE, sheet_name=0, dtype=str, engine=\"openpyxl\")\n",
    "aero_df[\"Ecosystem\"] = \"Aerospace\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f15559",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAMPLE: no [\"Aerospace\"] this time\n",
    "aero_sample = generate_samplesets(\n",
    "    aero_df,\n",
    "    \"Aerospace\",   # single ecosystem → function returns a DataFrame\n",
    "    n   = N,\n",
    "    tgt = YES_POLICY,\n",
    "    seed= SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca48d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now aero_sample is already the DataFrame you want\n",
    "aero_sample[\"Human_Label\"]   = \"\"\n",
    "eco_samples[\"Aerospace\"]     = aero_sample\n",
    "\n",
    "# re-export (same as before)\n",
    "keep_cols = [\"name\",\"domain\",\"permalink\",\"short_description\",\"description\",\"Human_Label\"]\n",
    "with pd.ExcelWriter(out_path, engine=\"xlsxwriter\") as writer:\n",
    "    for eco, df in eco_samples.items():\n",
    "        df_reduced = df.reindex(columns=keep_cols)\n",
    "        sheet = eco[:31] or \"Sheet\"\n",
    "        df_reduced.to_excel(writer, sheet_name=sheet, index=False)\n",
    "        ws   = writer.sheets[sheet]\n",
    "        wb   = writer.book\n",
    "        wrap = wb.add_format({\"text_wrap\": True, \"valign\": \"top\"})\n",
    "        ws.set_column(\"A:F\", 45, wrap)\n",
    "\n",
    "print(\"✔️ Updated workbook saved to:\", out_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (explore)",
   "language": "python",
   "name": "explore_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
